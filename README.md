# STL10-ResNET101

## Intuition behind Residual blocks:If the identity mapping is optimal, We can easily push the residuals to zero (F(x) = 0) than to fit an identity mapping (x, input=output) by a stack of non-linear layers. In simple language it is very easy to come up with a solution like F(x) =0 rather than F(x)=x using stack of non-linear cnn layers as function (Think about it). So, this function F(x) is what the authors called Residual function.


![plot](D:/deep learning research paper/cnn from scratch/New folder/New folder/1_WVs9ywVLLKjSUBZ_mnfFrw.png)
